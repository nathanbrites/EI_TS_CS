{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"dataset\" : \"bilan-electrique-demi-heure\",\n",
    "    \"rows\" : 10,\n",
    "    \"sort\" : \"horodate\"\n",
    "}\n",
    "\n",
    "url = \"https://data.enedis.fr/api/records/1.0/search/\"\n",
    "\n",
    "req = requests.get(url, params=params).json() # http request on open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.json_normalize(req, record_path=[\"records\"])\n",
    "column_rename_dict = {name : name[7:] for name in df.columns if name[:6] == \"fields\"}\n",
    "df.rename(columns=column_rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"horodate\", \"consommation_hta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "time data \"2023-04-07T21:30:00+00:00\" doesn't match format \"%Y-%m-%dT%H:%M+%S:%f\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mhorodate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mto_datetime(df[\u001b[39m\"\u001b[39;49m\u001b[39mhorodate\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      2\u001b[0m                \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY-\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm-\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39mT\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mH:\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mM+\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mS:\u001b[39;49m\u001b[39m%f\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\nbrites\\code\\EI_TS_CS\\venv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1050\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1048\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39mmap(cache_array)\n\u001b[0;32m   1049\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1050\u001b[0m         values \u001b[39m=\u001b[39m convert_listlike(arg\u001b[39m.\u001b[39;49m_values, \u001b[39mformat\u001b[39;49m)\n\u001b[0;32m   1051\u001b[0m         result \u001b[39m=\u001b[39m arg\u001b[39m.\u001b[39m_constructor(values, index\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mindex, name\u001b[39m=\u001b[39marg\u001b[39m.\u001b[39mname)\n\u001b[0;32m   1052\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[39m.\u001b[39mMutableMapping)):\n",
      "File \u001b[1;32mc:\\Users\\nbrites\\code\\EI_TS_CS\\venv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:453\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmixed\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 453\u001b[0m     \u001b[39mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[39mformat\u001b[39;49m, exact, errors)\n\u001b[0;32m    455\u001b[0m result, tz_parsed \u001b[39m=\u001b[39m objects_to_datetime64ns(\n\u001b[0;32m    456\u001b[0m     arg,\n\u001b[0;32m    457\u001b[0m     dayfirst\u001b[39m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    461\u001b[0m     allow_object\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m \u001b[39mif\u001b[39;00m tz_parsed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[39m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    466\u001b[0m     \u001b[39m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nbrites\\code\\EI_TS_CS\\venv\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:484\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    474\u001b[0m     arg,\n\u001b[0;32m    475\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    479\u001b[0m     errors: \u001b[39mstr\u001b[39m,\n\u001b[0;32m    480\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Index:\n\u001b[0;32m    481\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[39m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     result, timezones \u001b[39m=\u001b[39m array_strptime(arg, fmt, exact\u001b[39m=\u001b[39;49mexact, errors\u001b[39m=\u001b[39;49merrors, utc\u001b[39m=\u001b[39;49mutc)\n\u001b[0;32m    485\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(tz \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m tz \u001b[39min\u001b[39;00m timezones):\n\u001b[0;32m    486\u001b[0m         \u001b[39mreturn\u001b[39;00m _return_parsed_timezone_results(result, timezones, utc, name)\n",
      "File \u001b[1;32mc:\\Users\\nbrites\\code\\EI_TS_CS\\venv\\lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:530\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\nbrites\\code\\EI_TS_CS\\venv\\lib\\site-packages\\pandas\\_libs\\tslibs\\strptime.pyx:351\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"2023-04-07T21:30:00+00:00\" doesn't match format \"%Y-%m-%dT%H:%M+%S:%f\", at position 0. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "df[\"horodate\"] = pd.to_datetime(df[\"horodate\"],\n",
    "               format='yyy-MM-dd'T'HH:mm:ssZZZZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields.injection_rte': 'injection_rte',\n",
       " 'fields.pertes': 'pertes',\n",
       " 'fields.consommation_hta': 'consommation_hta',\n",
       " 'fields.soutirage_rte': 'soutirage_rte',\n",
       " 'fields.production_profilee_photovoltaique': 'production_profilee_photovoltaique',\n",
       " 'fields.temperature_normale_lissee': 'temperature_normale_lissee',\n",
       " 'fields.consommation_profilee_res': 'consommation_profilee_res',\n",
       " 'fields.production_profilee': 'production_profilee',\n",
       " 'fields.temperature_reelle_lissee': 'temperature_reelle_lissee',\n",
       " 'fields.production_eolien': 'production_eolien',\n",
       " 'fields.consommation_telerelevee_hta': 'consommation_telerelevee_hta',\n",
       " 'fields.production_telerelevee': 'production_telerelevee',\n",
       " 'fields.consommation_profilee_ent_bt': 'consommation_profilee_ent_bt',\n",
       " 'fields.consommation_profilee_pro': 'consommation_profilee_pro',\n",
       " 'fields.production_totale': 'production_totale',\n",
       " 'fields.consommation_profilee': 'consommation_profilee',\n",
       " 'fields.production_profilee_aut': 'production_profilee_aut',\n",
       " 'fields.consommation_totale': 'consommation_totale',\n",
       " 'fields.mois': 'mois',\n",
       " 'fields.consommation_profilee_ent_hta': 'consommation_profilee_ent_hta',\n",
       " 'fields.pseudo_rayonnement': 'pseudo_rayonnement',\n",
       " 'fields.soutirage_vers_autres_grd': 'soutirage_vers_autres_grd',\n",
       " 'fields.horodate': 'horodate',\n",
       " 'fields.consommation_telerelevee': 'consommation_telerelevee',\n",
       " 'fields.production_photovoltaique': 'production_photovoltaique'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_rename_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
